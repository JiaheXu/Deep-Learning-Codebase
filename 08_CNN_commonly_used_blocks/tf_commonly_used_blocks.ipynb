{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df83371c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00085301",
   "metadata": {},
   "source": [
    "# normal blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb3db3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def block1(name):\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(8, activation=tf.nn.relu),\n",
    "        tf.keras.layers.Dense(4, activation=tf.nn.relu)],\n",
    "        name=name)\n",
    "\n",
    "def block2():\n",
    "    net = tf.keras.Sequential()\n",
    "    for i in range(4):\n",
    "        # 在这里嵌套\n",
    "        net.add(block1(name=f'block {i}'))\n",
    "        #net.add(block1() ) must has a name\n",
    "    return net\n",
    "\n",
    "rgnet = tf.keras.Sequential()\n",
    "rgnet.add(block2())\n",
    "rgnet.add(tf.keras.layers.Dense(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830c8442",
   "metadata": {},
   "source": [
    "# VGG blocks (sequential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a5e010b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg_block(num_convs, num_channels):\n",
    "    blk = tf.keras.models.Sequential()\n",
    "    for _ in range(num_convs):\n",
    "        blk.add(tf.keras.layers.Conv2D(num_channels,kernel_size=3,\n",
    "                                    padding='same',activation='relu'))\n",
    "    blk.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "    return blk\n",
    "\n",
    "def vgg(conv_arch):\n",
    "    net = tf.keras.models.Sequential()\n",
    "    # 卷积层部分\n",
    "    for (num_convs, num_channels) in conv_arch:\n",
    "        net.add(vgg_block(num_convs, num_channels))\n",
    "    # 全连接层部分\n",
    "    net.add(tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(4096, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(4096, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(10)]))\n",
    "    return net\n",
    "\n",
    "\n",
    "# (num_convs, out_channels)\n",
    "conv_arch = ((1, 64), (1, 128), (2, 256), (2, 512), (2, 512))\n",
    "net = vgg(conv_arch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "305c4082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential output shape:\t (1, 112, 112, 64)\n",
      "Sequential output shape:\t (1, 56, 56, 128)\n",
      "Sequential output shape:\t (1, 28, 28, 256)\n",
      "Sequential output shape:\t (1, 14, 14, 512)\n",
      "Sequential output shape:\t (1, 7, 7, 512)\n",
      "Sequential output shape:\t (1, 10)\n"
     ]
    }
   ],
   "source": [
    "X = tf.random.uniform((1, 224, 224, 1))\n",
    "# 请注意这里与pytorch的区别\n",
    "for blk in net.layers:\n",
    "    X = blk(X)\n",
    "    print(blk.__class__.__name__,'output shape:\\t', X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51f6c09",
   "metadata": {},
   "source": [
    "# Inception block\n",
    "## 它们可以用各种滤波器尺寸探索图像，这意味着不同大小的滤波器可以有效地识别不同范围的图像细节。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa97bb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inception(tf.keras.Model):\n",
    "    # c1--c4是每条路径的输出通道数\n",
    "    def __init__(self, c1, c2, c3, c4):\n",
    "        super().__init__()\n",
    "        # 线路1，单1x1卷积层\n",
    "        self.p1_1 = tf.keras.layers.Conv2D(c1, 1, activation='relu')\n",
    "        # 线路2，1x1卷积层后接3x3卷积层\n",
    "        self.p2_1 = tf.keras.layers.Conv2D(c2[0], 1, activation='relu')\n",
    "        self.p2_2 = tf.keras.layers.Conv2D(c2[1], 3, padding='same',\n",
    "                                           activation='relu')\n",
    "        # 线路3，1x1卷积层后接5x5卷积层\n",
    "        self.p3_1 = tf.keras.layers.Conv2D(c3[0], 1, activation='relu')\n",
    "        self.p3_2 = tf.keras.layers.Conv2D(c3[1], 5, padding='same',\n",
    "                                           activation='relu')\n",
    "        # 线路4，3x3最大汇聚层后接1x1卷积层\n",
    "        self.p4_1 = tf.keras.layers.MaxPool2D(3, 1, padding='same')\n",
    "        self.p4_2 = tf.keras.layers.Conv2D(c4, 1, activation='relu')\n",
    "\n",
    "\n",
    "    def call(self, x):\n",
    "        p1 = self.p1_1(x)\n",
    "        p2 = self.p2_2(self.p2_1(x))\n",
    "        p3 = self.p3_2(self.p3_1(x))\n",
    "        p4 = self.p4_2(self.p4_1(x))\n",
    "        # 在通道维度上连结输出\n",
    "        return tf.keras.layers.Concatenate()([p1, p2, p3, p4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da73e8f2",
   "metadata": {},
   "source": [
    "# Residual block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7900a6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Residual(tf.keras.Model):  #@save\n",
    "    def __init__(self, num_channels, use_1x1conv=False, strides=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = tf.keras.layers.Conv2D(\n",
    "            num_channels, padding='same', kernel_size=3, strides=strides)\n",
    "        self.conv2 = tf.keras.layers.Conv2D(\n",
    "            num_channels, kernel_size=3, padding='same')\n",
    "        self.conv3 = None\n",
    "        if use_1x1conv:\n",
    "            self.conv3 = tf.keras.layers.Conv2D(\n",
    "                num_channels, kernel_size=1, strides=strides)\n",
    "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
    "        self.bn2 = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "    def call(self, X):\n",
    "        Y = tf.keras.activations.relu(self.bn1(self.conv1(X)))\n",
    "        Y = self.bn2(self.conv2(Y))\n",
    "        if self.conv3 is not None:\n",
    "            X = self.conv3(X)\n",
    "        Y += X\n",
    "        return tf.keras.activations.relu(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f687081",
   "metadata": {},
   "source": [
    "# Dense block\n",
    "## 每一层都要把前面所有层的信息结合起来"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f8923fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_channels):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.bn = tf.keras.layers.BatchNormalization()\n",
    "        self.relu = tf.keras.layers.ReLU()\n",
    "        self.conv = tf.keras.layers.Conv2D(\n",
    "            filters=num_channels, kernel_size=(3, 3), padding='same')\n",
    "\n",
    "        self.listLayers = [self.bn, self.relu, self.conv]\n",
    "\n",
    "    def call(self, x):\n",
    "        y = x\n",
    "        for layer in self.listLayers.layers:\n",
    "            y = layer(y)\n",
    "        y = tf.keras.layers.concatenate([x,y], axis=-1)\n",
    "        return y\n",
    "\n",
    "class DenseBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_convs, num_channels):\n",
    "        super(DenseBlock, self).__init__()\n",
    "        self.listLayers = []\n",
    "        for _ in range(num_convs):\n",
    "            self.listLayers.append(ConvBlock(num_channels))\n",
    "\n",
    "    def call(self, x):\n",
    "        for layer in self.listLayers.layers:\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7a6d2bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 8, 8, 23])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk = DenseBlock(2, 10)\n",
    "X = tf.random.uniform((4, 8, 8, 3))\n",
    "Y = blk(X)\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b70c75",
   "metadata": {},
   "source": [
    "# Transition block\n",
    "## 由于每个Dense block都会带来通道数的增加，使用过多则会过于复杂化模型。 而过渡层可以用来控制模型复杂度。 它通过 1×1 卷积层来减小通道数，并使用步幅为2的平均汇聚层减半高和宽，从而进一步降低模型复杂度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43135866",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransitionBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_channels, **kwargs):\n",
    "        super(TransitionBlock, self).__init__(**kwargs)\n",
    "        self.batch_norm = tf.keras.layers.BatchNormalization()\n",
    "        self.relu = tf.keras.layers.ReLU()\n",
    "        self.conv = tf.keras.layers.Conv2D(num_channels, kernel_size=1)\n",
    "        self.avg_pool = tf.keras.layers.AvgPool2D(pool_size=2, strides=2)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.batch_norm(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv(x)\n",
    "        return self.avg_pool(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28b3fc1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 4, 4, 10])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk = TransitionBlock(10)\n",
    "blk(Y).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b04e5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
